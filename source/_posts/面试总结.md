---
title: 面试总结
date: 2018-09-19 22:09:54
tags: [notes,面试总结]
---



2019秋招

<!--more-->

面试官名言：

。。。
>不同面试官的侧重点不一样，有的比较看重基础，有的比较看重项目经验，你的xxx还是不错的。。
>今天我们就聊到这里。。。你先回去等通知。。

### 关于数据结构

二分查找

给一个数组，除了两个数字只出现一次，其他的都出现两次，找出这两个数

判断一棵树是否是另一棵树的子树

链表反转

归并排序

String To Int

考虑：判断空串、判断空格、判断符号、判断数字（判断溢出）,注意index<s.length()

求第k大的数(复杂度是多少？时间复杂度O(n)，空间复杂度O(1))

### 关于算法

#### 算法原理：

XGBoost原理(如何并行)？

XGBoost和LightGBM区别、和RF区别？

RF原理？

SVM的核函数有哪些？

> 线性核、多项式核、径向基核（RBF）、傅里叶核、样条核、Sigmoid核

树如何分裂？分裂后熵应该变大还是变小？

熵的定义和意义、怎么计算熵？

>我们一般使用**信息量**来进行**不确定性**的度量。分布为$P(X)$随机变量$X$的自信息定义为：$-log(p(X))$。
>
>> 对于两个不相关的事件x和y，定义$I(x)$来表示时间的信息，则$I(x,y)=I(x)+I(y)$，而$P(x,y)=P(x)P(y)$。由此可知$I(x)$与$P(x)$的对数相关，则可定义$I(x)=-log(P(x))$，负数为了保证信息量为正数。
>
>**(信息)熵**定义为信息量关于随机变量$X$概率分布的期望，也就是定义为该随机变量所有可能发生的事件产生信息量的期望。（最短平均编码长度？）。
>
>> 1维随机变量：$H(X)=-\sum_xp(x)log(p(x))$
>>
>> 多维的联合熵：$H(X,Y)=-\sum_{x,y}p(x,y)log(p(x,y))=-\sum_{i=1}^{n}\sum_{j=1}^{m}p(x_i,y_i)log(p(x_i,y_i))$
>>
>> > 随机变量取值个数越多熵越大，当随机变量均匀分布时，熵最大。($0<H(X)<log(n)$)
>
>**条件熵**：$X$给定条件下$Y$的条件概率分布的熵对随机变量$X$的期望，条件熵 = 联合熵 - 单独熵。
>
>> $H(Y|X)=\sum_xp(x)H(Y|X=x)=-\sum_xp(x)\sum_yp(y|x)logp(y|x)=-\sum_x\sum_yp(x,y)logp(y,x)=-\sum_{x,y}p(x,y)logp(y|x)$
>>
>> $H(X,Y)=-\sum_{x,y}p(x,y)logp(x,y)=H(Y|X)+H(X)$
>>
>> $H(Y|X)=H(X,Y)-H(X)$
>
>**相对熵**（KL散度）：两个概率分布之间的差异。
>
>> $D_{KL}(p||q)=\sum_xp(x)log\frac{p(x)}{q(x)}$(p与q之间的对数差在p上的期望值)
>
>**交叉熵**：模型的分布与训练时分布的差异，当KL散度为0的时候，模型预测值得分布于训练集分布相同。
>
>> $H(p,q)=-\sum_xp(x)logq(x)$
>>
>> $H(p,q)=H(p)+D_{KL}(p||q)$
>
>熵与方差的关系(在大部分分布的情况下正相关？)
>
>**信息增益**：熵-条件熵
>
>**互信息**：联合分布于乘积分布之间的相对熵，熵-条件熵
>
>> $I(X;Y)=\sum_{x,y}p(x,y)log\frac{p(x,y)}{p(x)p(y)}=H(X)-H(X|Y)$

二分类的label，数据如何分布熵最大？

> 一半一半，均匀分布的时候

Bootstrap是什么？

> 有放回抽样?

Bagging和Boosting区别、Stacking？

> bagging：如果各个单独的模型产生的误差是不相关的，那么bagging后的平均误差可以仅仅通过M个版本求平均的方法减小M倍，但是实际应用中，误差通常是高度相关的。
>
> boosting：基分类器是顺序训练的，每个基分类器使用数据集的一个加权形式进行训练，其中与每个数据点相关的权系数依赖于前一个分类器的表现。被一个基分类器误分类的点在训练序列的下一个分类器时会被赋予更高的权重。Adaboost训练完毕后通过加权投票的方法进行组合。

协方差矩阵？

>标准差和方差都是用来描述一维数据，协方差是一种用来度量两个随机变量关系的统计量，是一个对称的方阵，对角线上的因子就是变量的方差。

pearson相关系数(如何定义)？

> 协方差/标准差乘积

评价指标有哪些(分类、回归)？

- R-Squared：$R^2 = 1 - \sum(y-\hat{y})^2/\sum(y-\bar{y})^2$，衡量回归方程与真实样本输出之间的相似程度。

  反映的是大概有多准，因为随着样本数增加R-Squared必然增加，无法真正定量说明准确程度。单独看R-Square并不能推断出特征是否有意义。应该使用校正决定系数（Adjusted R-Squared）

AUC怎么计算？ROC曲线怎么画？

降维的方法有哪些？

>缺失比例过滤
>
>低方差滤波（方差与信息熵关系）
>
>高相关滤波（注意保留与目标变量存在高相关性的列，高相关性的特征会使得线性回归逻辑回归的效果变差）
>
>树模型特征重要性
>
>前向特征选择，反向特征消除（加减特征看效果。。）
>
>因子分析（按相关性分组）
>
>PCA、ICA、IOSMAP、t-SNE、UMAP
>
>AutoEncoder、Word2Vec

如何做异常检测？

如何判断一个特征是否有用？

如何判断数据是线性的？

> 线性分类模型是指决策面是输入向量X的线性函数。定义为D维输入空间的D-1维超平面。如果数据集可以被线性决策面精确地分类，该数据集是线性可分的。
>
> 判断数据集是否线性可分：低维直接画图判断，高维检查凸包是否相交。

线性模型和非线性模型的区别？

>决策边界是线性，自变量（单变量时）x是否只受一个w影响，是w的线性函数，特征交叉是非线性模型（基函数非线性）。

CTR预估中如何处理样本不平衡的问题？

如何判断采样是否有效？

TextCNN原理？

Word2Vec原理？

FastText原理？

TFIDF，怎么计算，怎么改进？

TFIDF，有什么缺点？

> 优点：简单快速，容易理解。缺点：用词频来衡量文章中的一个词的重要性不够全面，有时候重要的词出现的不够多，而且这种计算无法体现位置信息，无法体现词在上下文中的重要性。如需体现词的上下文结构，需要使用Word2Vec。

N-gram怎么平滑？

拉普拉斯平滑？贝叶斯平滑？

聚类算法？硬核聚类软核聚类？

>只能有一个类别的叫硬核聚类，kmeans是硬核，GMM是软核

广义线性模型的理解？

> 符合指数分布族的一般模型

最小二乘和最大似然的关系？

>最小二乘：找到一组估计值，使得实际值与估计值距离最小                                                
>
>最大似然：寻找一组参数估计值，使得已发生的样本概率最大
>
>最小二乘是高斯噪声模型假设下的最大似然解？
>
>对于二分类问题，不适宜用最小平方法，

激活函数有哪些？ReLU和Sigmoid的区别有哪些？

参数化方法和非参数化方法？

> 线性回归是参数化的，kNN是非参数化的（基于记忆的方法）

逻辑回归为什么不用squareloss？

>

各种范数？

> $L_p$范数：向量各个元素绝对值的$p$次方求和，然后求$1/p$次方。
>
> $L_1$、$L_2$:向量各个元素绝对值之和，平方和然后求平方根。

各种距离？

> 曼哈顿距离、欧式距离、余弦距离、明式距离、pearson相关系数、

SVM数据量大时为什么速度慢？

> 大量的非支持向量参与训练过程，从而进行了大量的二次规划计算，导致分类计算量大、分类速度慢

SVM核函数如何选择？

> 1、样本特征很多时，特征的维数很高，往往可能线性可分，可以考虑线性核函数
>
> 2、样本数量很多，特征较少时，可以手动添加一些特征，在考虑线性核函数
>
> 3、样本特征维度不高，样本数量也不多，考虑高斯核函数（RBF核（指数核函数，拉普拉斯核函数）的一种）

#### 手推公式

LR

SVM(适用于特征维度多于样本数的情况？)

PCA

XGB

### 其他

##### SQL题

一个表包含Name，Subject，Score三个字段，输出总分前十名的同学

```sql
select Name,sum(Score) as SumScore from A group by Name order by SumScore limit 10; ?
```

##### 编程语言题

Python dict排序

```python
sorted(d.items(),key = lambda d:d[0])
sorted(d.items(),key = lambda d:d[1],reverse=True)
```

Python 有哪些数据类型结构？List和Dict的区别？

> list,dict,set,tuple
>
> collections(defaultdict、counter、deque、namedtuple、enum.Enum)
>
> [pythonGitbook](https://eastlakeside.gitbooks.io/interpy-zh/content/collections/collections.html)

> dict:
>
> - 查找和插入速度极快，且不会随着key的增加而增加
> - 占用大量内存
>
> list：
>
> - 查找和插入时间随着元素的增加而增加
> - 占用空间小，浪费内存少
>
> > dict的key必须是不可变对象，dict根据key计算value的存储位置（hash算法）

Python异常捕获？

```python
try:
    xxx
    raise Exception
except Exception as e:
    print(type(e))  ##捕捉到异常对象执行
else:
	print(1) ##不抛出异常执行    
finally:
    print(2)  ##无论如何都执行
```

Python生成器？

> 变循环，边计算的结构，节省空间（如果使用列表内存占用太大）

Python map、reduce函数？

```python
def char2num(s):
    return {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}[s]
def str2int(s):
    return reduce(lambda x,y:x*10+y,map(char2num,s))
#map
#reduce 把结果继续和下一个元素做累积运算
```

##### 大数据相关题

介绍下HDFS？

说下MapReduce原理？

高可用机制和联邦机制是什么？

高可用机制的备用是冷的还是热的？为什么？

如何对大文件中的数字排序？(文件很大机器内存有限)

爬取大量URL时，如何判断这个URL是否已经爬过？（set？布隆过滤器？）